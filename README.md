# Gradient-Descent-Technique-
Gradient Descent Technique, Implementation from scratch It started with implementing the function of gradient descent and then optimizing it with different techniques like Mini- Batch, Stochastic, Adagrad, Adam, RMSprop., Momentum, and NAG.
